name: TODO to GitHub Issues

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  issues: write
  contents: read

jobs:
  create-issues:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install PyGithub

      - name: Process TODOs
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO_NAME: ${{ github.repository }}
          COMMIT_SHA: ${{ github.sha }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import re
          from pathlib import Path
          from github import Github
          from collections import defaultdict
          import textwrap

          # Initialize GitHub client
          g = Github(os.environ['GITHUB_TOKEN'])
          repo = g.get_repo(os.environ['REPO_NAME'])
          commit_sha = os.environ['COMMIT_SHA']

          # Regex patterns for TODOs with optional metadata
          # Matches: TODO(TITLE: text, PRIORITY: high, TYPE: bug, ASSIGNEE: user, ...)
          canonical_pattern = re.compile(
              r'#\s*TODO\(TITLE:\s*([^,)]+)(?:,\s*([^)]*))?\)(?::\s*(.*))?',
              re.IGNORECASE
          )
          # Matches: TODO(REF: text, ...) or TODO(REF: text): description
          referenced_pattern = re.compile(
              r'#\s*TODO\(REF:\s*([^,)]+)(?:,\s*([^)]*))?\)(?::\s*(.*))?',
              re.IGNORECASE
          )

          # Storage
          canonical_todos = {}
          referenced_todos = defaultdict(list)
          existing_issues_map = {}

          # Label mapping for metadata
          PRIORITY_LABELS = {
              'critical': 'priority:critical',
              'high': 'priority:high',
              'medium': 'priority:medium',
              'low': 'priority:low'
          }
          
          TYPE_LABELS = {
              'bug': 'type:bug',
              'feature': 'type:feature',
              'refactor': 'type:refactor',
              'documentation': 'type:documentation',
              'test': 'type:test',
              'performance': 'type:performance',
              'security': 'type:security',
              'accessibility': 'type:accessibility'
          }
          
          EFFORT_LABELS = {
              'small': 'effort:small',
              'medium': 'effort:medium',
              'large': 'effort:large',
              'xlarge': 'effort:xlarge'
          }

          def parse_metadata(metadata_str):
              """Parse metadata string into dict of key-value pairs"""
              metadata = {}
              if not metadata_str:
                  return metadata
              
              # Split by comma and parse key:value pairs
              pairs = [p.strip() for p in metadata_str.split(',')]
              for pair in pairs:
                  if ':' in pair:
                      key, value = pair.split(':', 1)
                      metadata[key.strip().upper()] = value.strip()
              
              return metadata

          def extract_labels_from_metadata(metadata):
              """Convert metadata to GitHub labels"""
              labels = ['todo', 'tech-debt']
              
              # Add priority label
              if 'PRIORITY' in metadata:
                  priority = metadata['PRIORITY'].lower()
                  if priority in PRIORITY_LABELS:
                      labels.append(PRIORITY_LABELS[priority])
              
              # Add type label
              if 'TYPE' in metadata:
                  type_val = metadata['TYPE'].lower()
                  if type_val in TYPE_LABELS:
                      labels.append(TYPE_LABELS[type_val])
              
              # Add effort label
              if 'EFFORT' in metadata:
                  effort = metadata['EFFORT'].lower()
                  if effort in EFFORT_LABELS:
                      labels.append(EFFORT_LABELS[effort])
              
              # Add epic label
              if 'EPIC' in metadata:
                  labels.append(f"epic:{metadata['EPIC'].lower().replace(' ', '-')}")
              
              return labels

          print("=" * 80)
          print("SCANNING REPOSITORY FOR TODOs")
          print("=" * 80)

          # Scan repository for TODOs
          exclude_dirs = {'.git', '.venv', 'venv', 'node_modules', '__pycache__', '.pytest_cache', 'dist', 'build', 'docs'}
          exclude_extensions = {'.md', '.txt', '.rst', '.html', '.xml', '.json', '.yaml', '.yml', '.toml', '.ini', '.cfg'}
          code_extensions = {'.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.c', '.cpp', '.h', '.hpp', '.cs', '.go', '.rs', '.rb', '.php', '.sh', '.bash'}
          
          for file_path in Path('.').rglob('*'):
              # Skip filters
              if any(ex in file_path.parts for ex in exclude_dirs):
                  continue
              if not file_path.is_file():
                  continue
              if file_path.suffix.lower() in exclude_extensions:
                  continue
              if file_path.suffix.lower() not in code_extensions:
                  continue
              
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      for line_num, line in enumerate(f, 1):
                          # Check for canonical TODOs
                          canon_match = canonical_pattern.search(line)
                          if canon_match:
                              raw_title = canon_match.group(1).strip()
                              metadata_str = canon_match.group(2)
                              extra_desc = canon_match.group(3).strip() if canon_match.group(3) else ""
                              
                              metadata = parse_metadata(metadata_str)
                              
                              full_desc = raw_title
                              if extra_desc:
                                  full_desc += f": {extra_desc}"

                              if raw_title not in canonical_todos:
                                  canonical_todos[raw_title] = {
                                      'file': str(file_path),
                                      'line': line_num,
                                      'title': raw_title,
                                      'description': full_desc,
                                      'text': line.strip(),
                                      'metadata': metadata,
                                      'labels': extract_labels_from_metadata(metadata)
                                  }
                              continue

                          # Check for referenced TODOs
                          ref_match = referenced_pattern.search(line)
                          if ref_match:
                              raw_title = ref_match.group(1).strip()
                              metadata_str = ref_match.group(2)
                              extra_desc = ref_match.group(3).strip() if ref_match.group(3) else ""
                              
                              metadata = parse_metadata(metadata_str)
                              
                              referenced_todos[raw_title].append({
                                  'file': str(file_path),
                                  'line': line_num,
                                  'description': extra_desc if extra_desc else "Reference",
                                  'text': line.strip(),
                                  'metadata': metadata
                              })
                              continue

              except (UnicodeDecodeError, PermissionError) as e:
                  print(f"Warning: Could not read {file_path}: {e}")
                  continue

          print(f"\nFound {len(canonical_todos)} canonical TODO titles")
          print(f"Found {sum(len(v) for v in referenced_todos.values())} referenced TODOs")

          # Get existing issues with 'todo' label
          print("\n" + "=" * 80)
          print("CHECKING EXISTING ISSUES")
          print("=" * 80)
          
          try:
              for issue in repo.get_issues(state='all', labels=['todo']):
                  if issue.title.startswith("TODO: "):
                      extracted_title = issue.title[6:].strip()
                      existing_issues_map[extracted_title] = issue
              
              print(f"Found {len(existing_issues_map)} existing TODO issues")
          except Exception as e:
              print(f"Error fetching existing issues: {e}")

          # Create issues for NEW canonical TODOs
          print("\n" + "=" * 80)
          print("CREATING ISSUES FOR CANONICAL TODOs")
          print("=" * 80)

          created_count = 0
          for title_key, todo in canonical_todos.items():
              if title_key in existing_issues_map:
                  print(f"\nSkipping (already exists): {title_key[:60]}...")
                  continue

              try:
                  permalink = f"https://github.com/{os.environ['REPO_NAME']}/blob/{commit_sha}/{todo['file']}#L{todo['line']}"

                  # Build metadata section
                  metadata_section = ""
                  if todo['metadata']:
                      metadata_section = "\n### Metadata\n"
                      for key, value in todo['metadata'].items():
                          metadata_section += f"- **{key}**: {value}\n"

                  # Create issue body - using triple quotes for the markdown content
                  body_content = textwrap.dedent(f"""
                      **TODO:** {todo['description']}

                      **Location:** `{todo['file']}:{todo['line']}`  
                      **Permalink:** {permalink}  
                      **Commit:** {commit_sha[:7]}
                      {metadata_section}
                      ---

                      ### Code Context
                      ```
                      {todo['text']}
                      ```

                      ---

                      ### Related TODO References
                      _No related references found yet. References will be added automatically when found._
                  """).strip()

                  # Create the issue
                  issue = repo.create_issue(
                      title=f"TODO: {title_key}",
                      body=body_content,
                      labels=todo['labels']
                  )

                  # Auto-assign if specified
                  if 'ASSIGNEE' in todo['metadata']:
                      try:
                          assignee = todo['metadata']['ASSIGNEE']
                          issue.add_to_assignees(assignee)
                          print(f"   Assigned to: {assignee}")
                      except Exception as e:
                          print(f"   Could not assign to {assignee}: {e}")

                  print(f"\nCreated issue #{issue.number}: {title_key}")
                  print(f"   Labels: {', '.join(todo['labels'])}")
                  created_count += 1
                  existing_issues_map[title_key] = issue

              except Exception as e:
                  print(f"\nError creating issue for '{title_key}': {e}")

          print(f"\nCreated {created_count} new issues")

          # Update issues with referenced TODOs
          print("\n" + "=" * 80)
          print("UPDATING ISSUES WITH CROSS-REFERENCES")
          print("=" * 80)

          updated_count = 0
          
          all_titles_with_refs = set(referenced_todos.keys())
          
          for title_key in all_titles_with_refs:
              if title_key not in existing_issues_map:
                  print(f"\nFound {len(referenced_todos[title_key])} reference(s) for '{title_key}' but no canonical TODO or existing issue. Skipping.")
                  continue
              
              issue = existing_issues_map[title_key]
              refs = referenced_todos[title_key]

              try:
                  # Parse existing references from issue body
                  existing_refs_in_body = set()
                  if issue.body:
                      for line in issue.body.split('\n'):
                          if line.strip().startswith('- [ ]') and '`' in line:
                              match = re.search(r'`([^`]+:\d+)`', line)
                              if match:
                                  existing_refs_in_body.add(match.group(1))

                  new_refs_lines = []
                  for ref in refs:
                      ref_key = f"{ref['file']}:{ref['line']}"
                      if ref_key not in existing_refs_in_body:
                          permalink = f"https://github.com/{os.environ['REPO_NAME']}/blob/{commit_sha}/{ref['file']}#L{ref['line']}"
                          new_refs_lines.append(f"- [ ] [`{ref_key}`]({permalink}) â€“ {ref['description']}")

                  if new_refs_lines:
                      new_body = issue.body or ""
                      
                      header = "### Related TODO References"
                      
                      if header not in new_body:
                          # Header doesn't exist, add it
                          new_body += f"\n\n{header}\n" + "\n".join(new_refs_lines)
                      else:
                          # Header exists, find and replace the section
                          lines = new_body.split('\n')
                          header_idx = None
                          for i, line in enumerate(lines):
                              if header in line:
                                  header_idx = i
                                  break
                          
                          if header_idx is not None:
                              # Find where the section ends (next ### or end of file)
                              section_end = len(lines)
                              for i in range(header_idx + 1, len(lines)):
                                  if lines[i].startswith('###'):
                                      section_end = i
                                      break
                              
                              # Reconstruct body: before + header + old content + new refs + after
                              before = '\n'.join(lines[:header_idx + 1])
                              existing_refs = '\n'.join(lines[header_idx + 1:section_end])
                              after = '\n'.join(lines[section_end:]) if section_end < len(lines) else ""
                              
                              new_body = before + '\n' + existing_refs + '\n' + '\n'.join(new_refs_lines)
                              if after:
                                  new_body += '\n' + after
                      
                      issue.edit(body=new_body)
                      print(f"\nUpdated issue #{issue.number} ('{title_key}') with {len(new_refs_lines)} new reference(s)")
                      updated_count += 1
                  else:
                      print(f"\nIssue #{issue.number} already has all references for '{title_key}'")

              except Exception as e:
                  print(f"\nError updating issue #{issue.number}: {e}")

          print(f"\nUpdated {updated_count} issue(s) with cross-references")
          
          print("\n" + "=" * 80)
          print("SUMMARY")
          print("=" * 80)
          print(f"Canonical TODOs found: {len(canonical_todos)}")
          print(f"Issues created: {created_count}")
          print(f"Issues updated: {updated_count}")
          print("=" * 80)
          PYTHON_SCRIPT